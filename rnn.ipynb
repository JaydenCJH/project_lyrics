{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 08:40:04.048700: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 08:40:04.917138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482780\n"
     ]
    }
   ],
   "source": [
    "txt_file = 'eng_poprock_text.txt'\n",
    "raw_corpus = []\n",
    "\n",
    "with open(txt_file, 'r', encoding = 'utf-8') as f:\n",
    "    raw = f.read().splitlines()\n",
    "    raw_corpus.extend(raw)\n",
    "print(len(raw_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Get her name and get her number',\n",
       " 'Find out all of the things',\n",
       " 'that we have in common',\n",
       " 'Never all the differences,',\n",
       " 'oh, yeah']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()                         #소문자 변경 후 양쪽 공백 제거\n",
    "    sentence = re.sub(r\"([?.!,¿]).,\", r\" \\1 \", sentence)          #특수문자 양쪽에 공백 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                 #여러 개의 공백이 붙어있으면 하나의 공백으로\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣?!¿]+\", \" \", sentence)   #영어, 알파벳, ?, !, ¿ 제외 모두 공백으로\n",
    "    sentence = sentence.strip()                                 #양쪽 공백 제거\n",
    "    sentence = re.sub(r\"\\(.\\)\", \" \", sentence)                  #괄호 제거\n",
    "    sentence = '<start> ' + sentence + ' <end>'                 #start, end 추가\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentences sentence 그리고 <end>\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_sentence(\"This @_is, ;;;sample        (sentences) sentence . 그리고 \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458614\n",
      "['<start> get her name and get her number <end>', '<start> find out all of the things <end>', '<start> that we have in common <end>', '<start> never all the differences <end>', '<start> oh yeah <end>', '<start> meet her parents meet her brother <end>', '<start> then she starts sleepin <end>', '<start> over the crib on weekends <end>', '<start> like a real relationship oh no <end>', '<start> for me the stars are alignin <end>']\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0:\n",
    "        continue\n",
    "    if sentence[-1] == ':':\n",
    "        continue\n",
    "    if len(sentence)>150:\n",
    "        continue\n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "    \n",
    "print(len(corpus))\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 15000, filters = ' ', oov_token = '<unk>')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding = 'post')\n",
    "    print('토크나이저: ', tokenizer, '\\n', tensor)\n",
    "    \n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토크나이저:  <keras.src.legacy.preprocessing.text.Tokenizer object at 0x7f354351e210> \n",
      " [[   2   50  124 ...    0    0    0]\n",
      " [   2  136   55 ...    0    0    0]\n",
      " [   2   17   18 ...    0    0    0]\n",
      " ...\n",
      " [   2   13 2647 ...    0    0    0]\n",
      " [   2   13   13 ...    0    0    0]\n",
      " [   2 2647    3 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458614, 33)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  50, 124, 263,  10,  50, 124, 639,   3,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : you\n",
      "6 : the\n",
      "7 : it\n",
      "8 : to\n",
      "9 : me\n",
      "10 : and\n",
      "11 : t\n",
      "12 : a\n",
      "13 : my\n",
      "14 : s\n",
      "15 : m\n",
      "16 : in\n",
      "17 : that\n",
      "18 : we\n",
      "19 : your\n",
      "20 : on\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, ':', tokenizer.index_word[idx])\n",
    "    if idx>=20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서 길이:  (458614, 33)\n",
      "소스문장 길이:  32\n",
      "타겟문장 길이:  32\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]\n",
    "tgt_input = tensor[:, 1:]\n",
    "print('텐서 길이: ', tensor.shape)\n",
    "print('소스문장 길이: ', len(src_input[0]))\n",
    "print('타겟문장 길이: ', len(tgt_input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train 길이:  (366891, 32)\n",
      "Target Train 길이:  (366891, 32)\n",
      "Source Test 길이:  (91723, 32)\n",
      "Target Test 길이:  (91723, 32)\n"
     ]
    }
   ],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size = 0.2, random_state = 1234)\n",
    "print('Source Train 길이: ', enc_train.shape)\n",
    "print('Target Train 길이: ', dec_train.shape)\n",
    "print('Source Test 길이: ', enc_val.shape)\n",
    "print('Target Test 길이: ', dec_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 08:44:51.812907: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(256, 32), dtype=tf.int32, name=None), TensorSpec(shape=(256, 32), dtype=tf.int32, name=None))>\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(256, 32), dtype=tf.int32, name=None), TensorSpec(shape=(256, 32), dtype=tf.int32, name=None))>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 08:44:51.856542: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:44:51.856751: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:44:51.857724: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:44:51.857857: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:44:51.857943: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:44:52.948191: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:44:52.948348: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:44:52.948457: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:44:52.948540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12702 MB memory:  -> device: 0, name: NVIDIA A16-16Q, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epochs = len(src_input) // BATCH_SIZE\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "dataset_train = dataset_train.shuffle(BUFFER_SIZE)\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "dataset_val = dataset_val.shuffle(BUFFER_SIZE)\n",
    "dataset_val = dataset_val.batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "print(dataset_train)\n",
    "print(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.SimpleRNN(hidden_size, return_sequences = True)\n",
    "        self.rnn_2 = tf.keras.layers.SimpleRNN(hidden_size, return_sequences = True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TextGenerator name=text_generator, built=False>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size, hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 32, 15001), dtype=float32, numpy=\n",
       "array([[[-1.09156836e-02, -5.14465617e-03, -2.43031560e-03, ...,\n",
       "          1.87353883e-03,  5.67439711e-03,  1.68873146e-02],\n",
       "        [ 5.90630528e-03,  1.49891945e-02, -4.66381386e-03, ...,\n",
       "          1.41403414e-02, -7.17819436e-03, -2.77108327e-03],\n",
       "        [ 2.77650151e-02, -3.86346853e-03, -2.05258932e-03, ...,\n",
       "         -8.70823208e-03,  2.17143968e-02,  6.93459203e-03],\n",
       "        ...,\n",
       "        [-1.83818582e-02,  2.68293116e-02, -4.21943404e-02, ...,\n",
       "          7.75922090e-02, -1.38374999e-01, -6.86590523e-02],\n",
       "        [ 7.78025612e-02, -5.14944643e-02, -3.25751007e-02, ...,\n",
       "          2.87333820e-02, -2.16341361e-01, -9.11754593e-02],\n",
       "        [ 1.08602056e-02, -4.08893358e-03, -2.43628863e-03, ...,\n",
       "          1.66056585e-02, -6.12796582e-02, -2.38681212e-02]],\n",
       "\n",
       "       [[-1.09156836e-02, -5.14465617e-03, -2.43031560e-03, ...,\n",
       "          1.87353883e-03,  5.67439711e-03,  1.68873146e-02],\n",
       "        [ 6.81228191e-03,  5.62791852e-03, -9.42754280e-03, ...,\n",
       "          1.23335198e-02, -4.20984533e-03, -7.49642402e-03],\n",
       "        [-1.22636668e-02,  6.44578424e-04, -2.62882840e-02, ...,\n",
       "          1.75681375e-02,  2.71483138e-02, -6.29199669e-04],\n",
       "        ...,\n",
       "        [-2.07100306e-02,  9.21478216e-03,  3.53048332e-02, ...,\n",
       "          7.94881582e-03, -1.19290382e-01, -3.69111635e-02],\n",
       "        [ 3.23748104e-02,  7.74618238e-02, -2.22840477e-02, ...,\n",
       "          6.48981035e-02, -9.04506817e-02, -1.43913943e-02],\n",
       "        [ 5.15146889e-02, -8.51617455e-02, -5.17720683e-03, ...,\n",
       "         -2.47504842e-02, -1.45906553e-01, -9.26926211e-02]],\n",
       "\n",
       "       [[-1.09156836e-02, -5.14465617e-03, -2.43031560e-03, ...,\n",
       "          1.87353883e-03,  5.67439711e-03,  1.68873146e-02],\n",
       "        [-3.13693471e-03,  1.27486708e-02, -5.84637886e-03, ...,\n",
       "          5.70204388e-03, -5.40319318e-03, -2.06380170e-02],\n",
       "        [ 2.19252445e-02, -2.26452621e-03, -2.90932774e-04, ...,\n",
       "         -7.01498846e-03,  2.01095231e-02,  6.24334160e-03],\n",
       "        ...,\n",
       "        [ 1.13104388e-01,  2.75644697e-02,  1.51682720e-02, ...,\n",
       "         -6.00679452e-03, -1.63073078e-01, -7.84901809e-03],\n",
       "        [ 7.03008426e-03, -1.15944399e-03,  5.13947867e-02, ...,\n",
       "          2.90622190e-02, -1.40484557e-01, -3.90986307e-03],\n",
       "        [-5.27710058e-02,  7.60642886e-02,  5.05362414e-02, ...,\n",
       "          1.23065956e-01, -1.10057384e-01, -8.37543234e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.09156836e-02, -5.14465617e-03, -2.43031560e-03, ...,\n",
       "          1.87353883e-03,  5.67439711e-03,  1.68873146e-02],\n",
       "        [ 2.30405858e-05,  9.79237724e-03, -3.63557017e-03, ...,\n",
       "          3.13100230e-04, -7.76617043e-03, -1.13947988e-02],\n",
       "        [ 8.72078072e-03, -2.32633781e-02, -2.08737073e-03, ...,\n",
       "          4.27035242e-03,  2.71420889e-02,  1.36619052e-02],\n",
       "        ...,\n",
       "        [ 3.21423858e-02,  4.93403971e-02, -4.89908420e-02, ...,\n",
       "          1.25208989e-01, -1.16819434e-01,  8.14707875e-02],\n",
       "        [ 2.52327733e-02, -4.64872345e-02, -2.03026831e-03, ...,\n",
       "         -2.76719145e-02, -1.66095749e-01,  7.07631698e-04],\n",
       "        [ 9.78818908e-03, -8.95799845e-02,  1.93379819e-03, ...,\n",
       "         -5.98874539e-02,  2.93256752e-02,  7.38579407e-02]],\n",
       "\n",
       "       [[-1.09156836e-02, -5.14465617e-03, -2.43031560e-03, ...,\n",
       "          1.87353883e-03,  5.67439711e-03,  1.68873146e-02],\n",
       "        [-4.46538068e-03,  1.71458591e-02, -6.09722082e-03, ...,\n",
       "          4.77749808e-03,  3.50933895e-03, -1.29001886e-02],\n",
       "        [ 8.17766041e-03, -2.20513344e-02, -2.07115579e-02, ...,\n",
       "          1.44985020e-02,  3.04815900e-02,  1.43595086e-02],\n",
       "        ...,\n",
       "        [ 1.63186938e-01, -3.64153646e-02, -8.74945074e-02, ...,\n",
       "          4.25583459e-02, -8.50812048e-02,  1.68232739e-01],\n",
       "        [ 1.58847973e-01, -1.36947725e-02, -2.97118463e-02, ...,\n",
       "          7.00965151e-02, -1.28703192e-01, -2.32001767e-02],\n",
       "        [-1.39383189e-02, -7.92282633e-03,  5.13597168e-02, ...,\n",
       "         -6.32770434e-02, -8.32591020e-03,  5.69321290e-02]],\n",
       "\n",
       "       [[-1.09156836e-02, -5.14465617e-03, -2.43031560e-03, ...,\n",
       "          1.87353883e-03,  5.67439711e-03,  1.68873146e-02],\n",
       "        [-4.13058279e-03,  4.37589595e-03,  1.70149759e-03, ...,\n",
       "          6.61763363e-03, -5.60892839e-03, -2.17154680e-04],\n",
       "        [-1.60532398e-03, -8.88392515e-03, -2.68091559e-02, ...,\n",
       "          3.06997821e-03,  2.84063108e-02, -1.57626290e-02],\n",
       "        ...,\n",
       "        [-4.16579619e-02, -5.10611162e-02, -1.77159812e-02, ...,\n",
       "         -1.73154548e-02, -1.38779372e-01,  7.52570853e-03],\n",
       "        [-4.39558625e-02, -1.55340498e-02, -6.51852190e-02, ...,\n",
       "          3.68783250e-02, -1.75618634e-01, -5.04470654e-02],\n",
       "        [-9.99198779e-02,  6.15043193e-03,  6.22530654e-02, ...,\n",
       "          1.17128976e-01, -4.16367985e-02, -4.51058298e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset_train.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"text_generator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"text_generator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">15,376,025</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │     \u001b[38;5;34m3,840,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │     \u001b[38;5;34m1,311,744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │    \u001b[38;5;34m15,376,025\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,626,201</span> (86.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,626,201\u001b[0m (86.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,626,201</span> (86.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,626,201\u001b[0m (86.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_377702/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 08:46:13.469093: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 08:46:13.469426: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:46:13.469536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:46:13.469696: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:46:13.469788: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-08 08:46:13.469858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /device:GPU:0 with 12702 MB memory:  -> device: 0, name: NVIDIA A16-16Q, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712565991.492443  378459 service.cc:145] XLA service 0x7f3464005240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1712565991.492483  378459 service.cc:153]   StreamExecutor device (0): NVIDIA A16-16Q, Compute Capability 8.6\n",
      "2024-04-08 08:46:31.542320: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-08 08:46:32.002631: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712565992.510556  378570 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_61', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712565992.769651  378572 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_61', 1740 bytes spill stores, 2152 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712565995.345460  378571 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_63', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712565995.798652  378573 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_63', 1748 bytes spill stores, 2168 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712565998.429447  378459 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 870/1433\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 238ms/step - loss: 1.3931"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss, optimizer = optimizer)\n",
    "model.fit(dataset_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence = '<start>', max_len = 30):\n",
    "    #테스트를 위해 입력받은 init_sentence도 텐서 변환\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype = tf.int64)\n",
    "    end_token = tokenizer.word_index['<end>']\n",
    "    \n",
    "    #단어를 하나씩 예측해 문장 생성\n",
    "    while True:\n",
    "        #1. 입력받은 문장의 텐서 입력\n",
    "        predict = model(test_tensor)\n",
    "        #2. 예측된 값 중 가장 높은 확률인 word index를 출력\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis = -1), axis = -1)[:, -1]\n",
    "        #3. 2에서 예측된 word index를 문장 뒤에 붙임\n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis = 0)], axis = -1)\n",
    "        #4. 모델이 <end>를 예측했거나 max_len에 도달하면 문장 생성을 마침\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "        \n",
    "    generated = ''\n",
    "    #tokenizer를 활용해 word index를 단어로 하나씩 변환\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + ' '\n",
    "        \n",
    "    return generated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_lyrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
